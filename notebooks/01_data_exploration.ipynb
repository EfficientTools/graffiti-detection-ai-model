{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../')\n",
    "from src.data.dataset import GraffitiDataset, load_image_paths_from_file, get_label_path_from_image_path\n",
    "from src.utils.visualization import draw_yolo_labels\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fabf084",
   "metadata": {},
   "source": [
    "## 1. Load Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501463fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset configuration\n",
    "config_path = '../configs/dataset.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    dataset_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Dataset Configuration:\")\n",
    "print(f\"  Path: {dataset_config['path']}\")\n",
    "print(f\"  Number of classes: {dataset_config['nc']}\")\n",
    "print(f\"  Class names: {dataset_config['names']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb25d5b",
   "metadata": {},
   "source": [
    "## 2. Load Image Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c12ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "data_root = Path(dataset_config['path'])\n",
    "train_txt = data_root / dataset_config['train']\n",
    "val_txt = data_root / dataset_config['val']\n",
    "test_txt = data_root / dataset_config.get('test', 'test.txt')\n",
    "\n",
    "# Load image paths\n",
    "train_images = load_image_paths_from_file(str(train_txt), str(data_root)) if train_txt.exists() else []\n",
    "val_images = load_image_paths_from_file(str(val_txt), str(data_root)) if val_txt.exists() else []\n",
    "test_images = load_image_paths_from_file(str(test_txt), str(data_root)) if test_txt.exists() else []\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"  Training images: {len(train_images)}\")\n",
    "print(f\"  Validation images: {len(val_images)}\")\n",
    "print(f\"  Test images: {len(test_images)}\")\n",
    "print(f\"  Total images: {len(train_images) + len(val_images) + len(test_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c906b",
   "metadata": {},
   "source": [
    "## 3. Analyze Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b779b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_images_and_labels(image_paths):\n",
    "    \"\"\"Analyze image dimensions and label statistics.\"\"\"\n",
    "    stats = {\n",
    "        'widths': [],\n",
    "        'heights': [],\n",
    "        'num_objects': [],\n",
    "        'class_counts': defaultdict(int),\n",
    "        'box_widths': [],\n",
    "        'box_heights': [],\n",
    "        'box_areas': []\n",
    "    }\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        # Load image\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        h, w = img.shape[:2]\n",
    "        stats['widths'].append(w)\n",
    "        stats['heights'].append(h)\n",
    "        \n",
    "        # Load labels\n",
    "        label_path = get_label_path_from_image_path(img_path)\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = [line.strip() for line in f if line.strip()]\n",
    "            \n",
    "            stats['num_objects'].append(len(lines))\n",
    "            \n",
    "            for line in lines:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    box_w = float(parts[3])\n",
    "                    box_h = float(parts[4])\n",
    "                    \n",
    "                    stats['class_counts'][class_id] += 1\n",
    "                    stats['box_widths'].append(box_w)\n",
    "                    stats['box_heights'].append(box_h)\n",
    "                    stats['box_areas'].append(box_w * box_h)\n",
    "        else:\n",
    "            stats['num_objects'].append(0)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "print(\"Analyzing training set...\")\n",
    "train_stats = analyze_images_and_labels(train_images)\n",
    "\n",
    "print(\"Analyzing validation set...\")\n",
    "val_stats = analyze_images_and_labels(val_images)\n",
    "\n",
    "print(\"Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f2d8c",
   "metadata": {},
   "source": [
    "## 4. Visualize Image Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e74b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Width distribution\n",
    "axes[0].hist(train_stats['widths'], bins=30, alpha=0.7, label='Train', color='blue')\n",
    "axes[0].hist(val_stats['widths'], bins=30, alpha=0.7, label='Val', color='orange')\n",
    "axes[0].set_xlabel('Image Width (pixels)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Image Width Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Height distribution\n",
    "axes[1].hist(train_stats['heights'], bins=30, alpha=0.7, label='Train', color='blue')\n",
    "axes[1].hist(val_stats['heights'], bins=30, alpha=0.7, label='Val', color='orange')\n",
    "axes[1].set_xlabel('Image Height (pixels)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Image Height Distribution')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average image size (train): {np.mean(train_stats['widths']):.0f} x {np.mean(train_stats['heights']):.0f}\")\n",
    "print(f\"Average image size (val): {np.mean(val_stats['widths']):.0f} x {np.mean(val_stats['heights']):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4255c28a",
   "metadata": {},
   "source": [
    "## 5. Analyze Objects per Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Objects per image\n",
    "axes[0].hist(train_stats['num_objects'], bins=range(0, max(train_stats['num_objects'])+2), \n",
    "             alpha=0.7, label='Train', color='blue')\n",
    "axes[0].set_xlabel('Number of Objects per Image')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Objects per Image Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Class distribution\n",
    "class_ids = list(train_stats['class_counts'].keys())\n",
    "class_counts = [train_stats['class_counts'][cid] for cid in class_ids]\n",
    "class_names = [dataset_config['names'][cid] for cid in class_ids]\n",
    "\n",
    "axes[1].bar(class_names, class_counts, color='green', alpha=0.7)\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylabel('Number of Instances')\n",
    "axes[1].set_title('Class Distribution (Training Set)')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average objects per image (train): {np.mean(train_stats['num_objects']):.2f}\")\n",
    "print(f\"Max objects per image (train): {max(train_stats['num_objects'])}\")\n",
    "print(f\"Total annotations (train): {sum(train_stats['num_objects'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470d7292",
   "metadata": {},
   "source": [
    "## 6. Analyze Bounding Box Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57650e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Box width distribution\n",
    "axes[0].hist(train_stats['box_widths'], bins=50, alpha=0.7, color='purple')\n",
    "axes[0].set_xlabel('Normalized Box Width')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Bounding Box Width Distribution')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box height distribution\n",
    "axes[1].hist(train_stats['box_heights'], bins=50, alpha=0.7, color='brown')\n",
    "axes[1].set_xlabel('Normalized Box Height')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Bounding Box Height Distribution')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Box area distribution\n",
    "axes[2].hist(train_stats['box_areas'], bins=50, alpha=0.7, color='teal')\n",
    "axes[2].set_xlabel('Normalized Box Area')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Bounding Box Area Distribution')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average box width: {np.mean(train_stats['box_widths']):.3f}\")\n",
    "print(f\"Average box height: {np.mean(train_stats['box_heights']):.3f}\")\n",
    "print(f\"Average box area: {np.mean(train_stats['box_areas']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5693a0e",
   "metadata": {},
   "source": [
    "## 7. Visualize Sample Images with Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select random samples\n",
    "n_samples = 6\n",
    "sample_indices = np.random.choice(len(train_images), min(n_samples, len(train_images)), replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, ax in enumerate(axes):\n",
    "    if idx < len(sample_indices):\n",
    "        img_path = train_images[sample_indices[idx]]\n",
    "        label_path = get_label_path_from_image_path(img_path)\n",
    "        \n",
    "        # Load image\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load labels\n",
    "        labels = []\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        labels.append([float(p) for p in parts[:5]])\n",
    "        \n",
    "        labels = np.array(labels) if labels else np.zeros((0, 5))\n",
    "        \n",
    "        # Draw labels\n",
    "        if len(labels) > 0:\n",
    "            img = draw_yolo_labels(img, labels, dataset_config['names'])\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Sample {idx+1} ({len(labels)} objects)\")\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e417af6",
   "metadata": {},
   "source": [
    "## 8. Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e2b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = {\n",
    "    'Split': ['Train', 'Validation', 'Test', 'Total'],\n",
    "    'Images': [\n",
    "        len(train_images),\n",
    "        len(val_images),\n",
    "        len(test_images),\n",
    "        len(train_images) + len(val_images) + len(test_images)\n",
    "    ],\n",
    "    'Annotations': [\n",
    "        sum(train_stats['num_objects']),\n",
    "        sum(val_stats['num_objects']),\n",
    "        0,  # Not analyzed\n",
    "        sum(train_stats['num_objects']) + sum(val_stats['num_objects'])\n",
    "    ],\n",
    "    'Avg Objects/Image': [\n",
    "        f\"{np.mean(train_stats['num_objects']):.2f}\" if train_stats['num_objects'] else 'N/A',\n",
    "        f\"{np.mean(val_stats['num_objects']):.2f}\" if val_stats['num_objects'] else 'N/A',\n",
    "        'N/A',\n",
    "        'N/A'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Dataset Summary\")\n",
    "print(\"=\"*60)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac3ed3",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Data Collection**: If the dataset is empty, collect and annotate graffiti images\n",
    "2. **Data Augmentation**: Review augmentation strategies in `src/data/augmentation.py`\n",
    "3. **Model Training**: Start training with `python scripts/train.py`\n",
    "4. **Hyperparameter Tuning**: Adjust training parameters based on dataset characteristics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
