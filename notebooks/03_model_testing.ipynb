{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b446475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../')\n",
    "from src.utils.visualization import draw_boxes, visualize_detection\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9edb03e",
   "metadata": {},
   "source": [
    "## 1. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b38247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to trained model\n",
    "model_path = '../models/best.pt'  # Update this path\n",
    "\n",
    "# Check if model exists\n",
    "if Path(model_path).exists():\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    model = YOLO(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "    \n",
    "    # Print model info\n",
    "    print(f\"\\nModel Summary:\")\n",
    "    print(f\"  Task: {model.task}\")\n",
    "    print(f\"  Device: {model.device}\")\n",
    "else:\n",
    "    print(f\"⚠️  Model not found at {model_path}\")\n",
    "    print(\"Please train a model first using: python scripts/train.py\")\n",
    "    print(\"\\nFor testing purposes, we'll load a pretrained YOLOv8 model:\")\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    print(\"Loaded pretrained YOLOv8n model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562c7a6",
   "metadata": {},
   "source": [
    "## 2. Load Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc73770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset configuration for class names\n",
    "config_path = '../configs/dataset.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    dataset_config = yaml.safe_load(f)\n",
    "\n",
    "class_names = dataset_config['names']\n",
    "print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c47d7",
   "metadata": {},
   "source": [
    "## 3. Single Image Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6712ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image_path, conf_threshold=0.25, iou_threshold=0.45):\n",
    "    \"\"\"Run inference on a single image.\"\"\"\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Run inference\n",
    "    results = model.predict(\n",
    "        source=image_path,\n",
    "        conf=conf_threshold,\n",
    "        iou=iou_threshold,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "    \n",
    "    # Extract predictions\n",
    "    boxes = results.boxes.xyxy.cpu().numpy()\n",
    "    scores = results.boxes.conf.cpu().numpy()\n",
    "    labels = results.boxes.cls.cpu().numpy().astype(int)\n",
    "    \n",
    "    # Draw boxes\n",
    "    if len(boxes) > 0:\n",
    "        image_rgb = draw_boxes(\n",
    "            image_rgb,\n",
    "            boxes,\n",
    "            labels.tolist(),\n",
    "            scores,\n",
    "            class_names\n",
    "        )\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(f'Detections: {len(boxes)} objects found')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print details\n",
    "    print(f\"\\nImage: {Path(image_path).name}\")\n",
    "    print(f\"Detections: {len(boxes)}\")\n",
    "    \n",
    "    if len(boxes) > 0:\n",
    "        print(\"\\nDetailed Results:\")\n",
    "        for i, (box, score, label) in enumerate(zip(boxes, scores, labels)):\n",
    "            class_name = class_names[label] if label in class_names else f\"Class {label}\"\n",
    "            print(f\"  {i+1}. {class_name}: {score:.3f} - [{box[0]:.1f}, {box[1]:.1f}, {box[2]:.1f}, {box[3]:.1f}]\")\n",
    "    \n",
    "    return boxes, scores, labels\n",
    "\n",
    "# Example: Test on a sample image\n",
    "# Replace with your own image path\n",
    "test_image = '../data/images/test/sample.jpg'  # Update this path\n",
    "\n",
    "if Path(test_image).exists():\n",
    "    results = run_inference(test_image, conf_threshold=0.25)\n",
    "else:\n",
    "    print(f\"Test image not found: {test_image}\")\n",
    "    print(\"Please provide a valid image path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd195e",
   "metadata": {},
   "source": [
    "## 4. Batch Inference on Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766613d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_inference(image_dir, conf_threshold=0.25, max_display=6):\n",
    "    \"\"\"Run inference on all images in a directory.\"\"\"\n",
    "    image_dir = Path(image_dir)\n",
    "    \n",
    "    # Find all images\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(image_dir.glob(f\"*{ext}\"))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No images found in {image_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images\")\n",
    "    \n",
    "    # Display first N results\n",
    "    n_display = min(max_display, len(image_files))\n",
    "    n_cols = 3\n",
    "    n_rows = (n_display + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6*n_rows))\n",
    "    axes = axes.flatten() if n_display > 1 else [axes]\n",
    "    \n",
    "    all_detections = []\n",
    "    \n",
    "    for i, img_path in enumerate(image_files):\n",
    "        # Run inference\n",
    "        image = cv2.imread(str(img_path))\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        results = model.predict(\n",
    "            source=str(img_path),\n",
    "            conf=conf_threshold,\n",
    "            verbose=False\n",
    "        )[0]\n",
    "        \n",
    "        boxes = results.boxes.xyxy.cpu().numpy()\n",
    "        scores = results.boxes.conf.cpu().numpy()\n",
    "        labels = results.boxes.cls.cpu().numpy().astype(int)\n",
    "        \n",
    "        all_detections.append(len(boxes))\n",
    "        \n",
    "        # Draw and display\n",
    "        if i < n_display:\n",
    "            if len(boxes) > 0:\n",
    "                image_rgb = draw_boxes(image_rgb, boxes, labels.tolist(), scores, class_names)\n",
    "            \n",
    "            axes[i].imshow(image_rgb)\n",
    "            axes[i].set_title(f\"{img_path.name}\\n{len(boxes)} detections\")\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for i in range(n_display, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nBatch Inference Summary:\")\n",
    "    print(f\"  Total images: {len(image_files)}\")\n",
    "    print(f\"  Total detections: {sum(all_detections)}\")\n",
    "    print(f\"  Average detections per image: {np.mean(all_detections):.2f}\")\n",
    "    print(f\"  Images with detections: {sum(1 for d in all_detections if d > 0)}\")\n",
    "\n",
    "# Example: Run batch inference\n",
    "test_dir = '../data/images/test'  # Update this path\n",
    "\n",
    "if Path(test_dir).exists():\n",
    "    batch_inference(test_dir, conf_threshold=0.25, max_display=6)\n",
    "else:\n",
    "    print(f\"Test directory not found: {test_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a51636",
   "metadata": {},
   "source": [
    "## 5. Adjust Detection Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aaff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_thresholds(image_path, thresholds=[0.1, 0.25, 0.5, 0.75]):\n",
    "    \"\"\"Compare detection results at different confidence thresholds.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, threshold in enumerate(thresholds):\n",
    "        # Run inference\n",
    "        results = model.predict(\n",
    "            source=image_path,\n",
    "            conf=threshold,\n",
    "            verbose=False\n",
    "        )[0]\n",
    "        \n",
    "        boxes = results.boxes.xyxy.cpu().numpy()\n",
    "        scores = results.boxes.conf.cpu().numpy()\n",
    "        labels = results.boxes.cls.cpu().numpy().astype(int)\n",
    "        \n",
    "        # Draw boxes\n",
    "        img_display = image_rgb.copy()\n",
    "        if len(boxes) > 0:\n",
    "            img_display = draw_boxes(img_display, boxes, labels.tolist(), scores, class_names)\n",
    "        \n",
    "        axes[idx].imshow(img_display)\n",
    "        axes[idx].set_title(f\"Confidence threshold: {threshold}\\n{len(boxes)} detections\")\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example: Compare thresholds\n",
    "if Path(test_image).exists():\n",
    "    compare_thresholds(test_image, thresholds=[0.1, 0.25, 0.5, 0.75])\n",
    "else:\n",
    "    print(\"Please provide a valid test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a1d86",
   "metadata": {},
   "source": [
    "## 6. Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a83c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a trained model, you can analyze its performance\n",
    "if Path(model_path).exists():\n",
    "    print(\"Model Performance Metrics:\")\n",
    "    print(\"(Run evaluation script for detailed metrics)\")\n",
    "    print(\"\\nTo evaluate your model, run:\")\n",
    "    print(\"  python scripts/evaluate.py --model models/best.pt --data configs/dataset.yaml\")\n",
    "else:\n",
    "    print(\"No trained model available yet.\")\n",
    "    print(\"Train a model first using:\")\n",
    "    print(\"  python scripts/train.py --data configs/dataset.yaml --epochs 100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0577b60d",
   "metadata": {},
   "source": [
    "## 7. Export Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(model_path, format='onnx'):\n",
    "    \"\"\"Export model to different formats for deployment.\"\"\"\n",
    "    if not Path(model_path).exists():\n",
    "        print(f\"Model not found: {model_path}\")\n",
    "        return\n",
    "    \n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    print(f\"Exporting model to {format.upper()} format...\")\n",
    "    \n",
    "    try:\n",
    "        export_path = model.export(format=format)\n",
    "        print(f\"✓ Model exported successfully to: {export_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Export failed: {e}\")\n",
    "\n",
    "# Example: Export to ONNX format\n",
    "if Path(model_path).exists():\n",
    "    print(\"\\nAvailable export formats:\")\n",
    "    print(\"  - onnx: Cross-platform deployment\")\n",
    "    print(\"  - torchscript: PyTorch deployment\")\n",
    "    print(\"  - coreml: iOS/macOS deployment\")\n",
    "    print(\"  - engine: TensorRT for NVIDIA GPUs\")\n",
    "    print(\"  - tflite: TensorFlow Lite for mobile\")\n",
    "    print(\"\\nTo export, uncomment and run:\")\n",
    "    print(\"  # export_model(model_path, format='onnx')\")\n",
    "else:\n",
    "    print(\"Train a model first before exporting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ea7bf",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Collect More Data**: Improve model by adding more diverse graffiti examples\n",
    "2. **Fine-tune**: Adjust hyperparameters based on performance\n",
    "3. **Deploy**: Export model and integrate into your application\n",
    "4. **Monitor**: Track real-world performance and retrain as needed"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
